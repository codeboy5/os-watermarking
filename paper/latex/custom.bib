% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@inproceedings{kirchenbauer2023watermark,
  title        = {A watermark for large language models},
  author       = {Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  booktitle    = {International Conference on Machine Learning},
  pages        = {17061--17084},
  year         = {2023},
  organization = {PMLR}
}

@misc{aaronson2023reform,
  author       = {Scott Aaronson},
  title        = {{20 - 'Reform' AI Alignment with Scott Aaronson}},
  year         = {2023},
  howpublished = {\url{https://axrp.net/episode/2023/04/11/episode-20-reform-ai-alignment-scott-aaronson.html}},
  note         = {AXRP - The AI X-risk Research Podcast}
}

@article{kuditipudi2023robust,
  title   = {Robust distortion-free watermarks for language models},
  author  = {Kuditipudi, Rohith and Thickstun, John and Hashimoto, Tatsunori and Liang, Percy},
  journal = {arXiv preprint arXiv:2307.15593},
  year    = {2023}
}

@article{liu2024adaptive,
  title   = {Adaptive text watermark for large language models},
  author  = {Liu, Yepeng and Bu, Yuheng},
  journal = {arXiv preprint arXiv:2401.13927},
  year    = {2024}
}

@article{christ2024provably,
  title   = {Provably Robust Watermarks for Open-Source Language Models},
  author  = {Christ, Miranda and Gunn, Sam and Malkin, Tal and Raykova, Mariana},
  journal = {arXiv preprint arXiv:2410.18861},
  year    = {2024}
}

@article{gu2023learnability,
  title   = {On the learnability of watermarks for language models},
  author  = {Gu, Chenchen and Li, Xiang Lisa and Liang, Percy and Hashimoto, Tatsunori},
  journal = {arXiv preprint arXiv:2312.04469},
  year    = {2023}
}

@article{block2025gaussmark,
  title   = {GaussMark: A Practical Approach for Structural Watermarking of Language Models},
  author  = {Block, Adam and Sekhari, Ayush and Rakhlin, Alexander},
  journal = {arXiv preprint arXiv:2501.13941},
  year    = {2025}
}

@article{gloaguen2025towards,
  title   = {Towards Watermarking of Open-Source LLMs},
  author  = {Gloaguen, Thibaud and JovanoviÄ‡, Nikola and Staab, Robin and Vechev, Martin},
  journal = {arXiv preprint arXiv:2502.10525},
  year    = {2025}
}


@inproceedings{ajith-etal-2024-downstream,
  title     = {Downstream Trade-offs of a Family of Text Watermarks},
  author    = {Ajith, Anirudh  and
               Singh, Sameer  and
               Pruthi, Danish},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-emnlp.821/},
  doi       = {10.18653/v1/2024.findings-emnlp.821},
  pages     = {14039--14053}
}

@misc{xu2024learningwatermarkllmgeneratedtext,
  title         = {Learning to Watermark LLM-generated Text via Reinforcement Learning},
  author        = {Xiaojun Xu and Yuanshun Yao and Yang Liu},
  year          = {2024},
  eprint        = {2403.10553},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2403.10553}
}

@article{elhassan2025can,
  title   = {Can you Finetune your Binoculars? Embedding Text Watermarks into the Weights of Large Language Models},
  author  = {Elhassan, Fay and Ajroldi, Niccol{\`o} and Orvieto, Antonio and Geiping, Jonas},
  journal = {arXiv preprint arXiv:2504.06446},
  year    = {2025}
}

@article{hu2022lora,
  title   = {Lora: Low-rank adaptation of large language models.},
  author  = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal = {ICLR},
  volume  = {1},
  number  = {2},
  pages   = {3},
  year    = {2022}
}