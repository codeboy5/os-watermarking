{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d599ff728f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import time \n",
    "import einops\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from rich import print as rprint\n",
    "from typing import Dict, List\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessorList\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "#model_name = \"EleutherAI/pythia-1b\"\n",
    "#model_name = \"/assets/models/meta-llama-3.1-8b\"\n",
    "load_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fac545e5f9e40aa9671864d19acd7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if load_model:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                                 device_map=\"auto\")\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "# extract the embed_token layer and purge the model from memory\n",
    "w = model.model.embed_tokens.weight.data.detach().clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "import gc\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset with `[X,y]` with `X=h(t)` and `y=token(t)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2759739/2044593793.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_dataset = torch.load(f\"data/X_dataset_{model_suffix}.pt\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_suffix \u001b[38;5;241m=\u001b[39m model_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m X_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/X_dataset_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_suffix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/y_dataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.12/site-packages/torch/serialization.py:1772\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1769\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset : storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1772\u001b[0m         \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[1;32m   1774\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1775\u001b[0m     )\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_suffix = model_name.split(\"/\")[-1]\n",
    "\n",
    "X_dataset = torch.load(f\"data/X_dataset_{model_suffix}.pt\")\n",
    "y_dataset = torch.load(f\"data/y_dataset_{model_suffix}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = X_dataset.shape[0]\n",
    "perm = torch.randperm(dataset_size)\n",
    "\n",
    "train_size = int(0.8 * dataset_size)\n",
    "\n",
    "X_train, y_train = X_dataset[ perm[:train_size] ], y_dataset[ perm[:train_size] ]\n",
    "X_val, y_val = X_dataset[ perm[train_size:] ], y_dataset[ perm[train_size:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size:  torch.Size([1310720, 4096])\n",
      "Val Dataset Size:  torch.Size([327680, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Size: \", X_train.shape)\n",
    "print(\"Val Dataset Size: \", X_val.shape)\n",
    "hidden_dim = X_dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and standard deviation\n",
    "mean = torch.mean(X_train, dim=0)\n",
    "std = torch.std(X_train, dim=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear probe for current token classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Derive soft labels from inverse transformations of token embeddings using the psuedoinverse of the embedding layer matrix\n",
    "- Train linear model without bias using MSE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -4.74090084026102e-05\n",
      "Standard Deviation: 0.016960974782705307\n"
     ]
    }
   ],
   "source": [
    "#w = model.gpt_neox.embed_in.weight.data\n",
    "#w = model.model.embed_tokens.weight.data\n",
    "mean = torch.mean(w)\n",
    "std_dev = torch.std(w)\n",
    "print(\"Mean:\", mean.item())\n",
    "print(\"Standard Deviation:\", std_dev.item())\n",
    "w_pinv = torch.pinverse(w)\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "# Initialize linear model with w_pinv   \n",
    "# with torch.no_grad():\n",
    "#     linear_nn.fc1.weight.copy_(w_pinv.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of w_pinv assigning max value to the right token: 99.65%\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct all embeddings using w_pinv\n",
    "\n",
    "# w_chunks = torch.chunk(w, torch.cuda.device_count(), dim=0)\n",
    "\n",
    "# results = []\n",
    "# for i, w_chunk in enumerate(w_chunks):\n",
    "#     with torch.cuda.device(i):\n",
    "#         results.append(torch.matmul(w_chunk.cuda(i), w_pinv.cuda(i)))\n",
    "\n",
    "# results = [result.to(\"cuda:1\") for result in results]\n",
    "\n",
    "# one_hot_recon = torch.cat(results, dim=0)\n",
    "\n",
    "one_hot_recon = torch.matmul(w, w_pinv)\n",
    "\n",
    "\n",
    "# Find the indices of the maximum values in the reconstructions\n",
    "predicted_indices = one_hot_recon.argmax(dim=1)\n",
    "# Count how many predictions match their respective indices\n",
    "correct_count = (predicted_indices == torch.arange(vocab_size, device=device)).sum().item()\n",
    "\n",
    "accuracy = correct_count / vocab_size\n",
    "print(f\"Accuracy of w_pinv assigning max value to the right token: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(tensor, K):\n",
    "    clusters = []\n",
    "    for k in range(K, 0, -1):\n",
    "        _, top_k_indices = torch.topk(tensor, k, dim=1)\n",
    "\n",
    "        sorted_top_k_indices = torch.sort(top_k_indices, dim=1)[0]\n",
    "\n",
    "        unique_rows, inverse_indices, counts = torch.unique(\n",
    "            sorted_top_k_indices, dim=0, return_inverse=True, return_counts=True)\n",
    "\n",
    "        k_clusters = unique_rows[counts == k]\n",
    "        k_clusters_indices = inverse_indices[k_clusters]\n",
    "        row_equality = (k_clusters_indices ==\n",
    "                        k_clusters_indices[:, 0:1]).all(dim=1)\n",
    "        assert row_equality.all(), \"Row equality check failed!\"\n",
    "\n",
    "        # Remove subsets of the last added list of larger clusters\n",
    "        valid_clusters = []\n",
    "        if len(clusters) > 0:  \n",
    "            # Check against all indices of every cluster\n",
    "            indices = set(torch.cat([c.flatten() for c in clusters], dim=0).tolist())\n",
    "            mask = torch.tensor([\n",
    "                set(row.tolist()).issubset(indices) for row in k_clusters\n",
    "            ])\n",
    "            valid_clusters = k_clusters[~mask]\n",
    "\n",
    "        else:  # If no larger clusters exist, all are valid\n",
    "            valid_clusters = k_clusters\n",
    "\n",
    "        clusters.append(valid_clusters)\n",
    "\n",
    "    # for each tensor in cluster, convert to list of 1D tensors\n",
    "    clusters = [cluster.tolist() for cluster in clusters]\n",
    "    # create on giant list of clusters\n",
    "    clusters = [cluster for sublist in clusters for cluster in sublist]\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = find_clusters(one_hot_recon, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the clusters\n",
    "flat_clusters = [item for sublist in clusters for item in sublist]\n",
    "# check for duplicates\n",
    "assert len(flat_clusters) == len(set(flat_clusters)), \"Duplicates found in clusters\"\n",
    "\n",
    "# convert list of lists to list of tensors\n",
    "clusters = [torch.tensor(cluster, device=one_hot_recon.device) for cluster in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new tensor to store the merged values\n",
    "merged_one_hot_recon = torch.zeros((len(clusters), len(clusters)), device=one_hot_recon.device)\n",
    "\n",
    "merged_rows = torch.stack([one_hot_recon[c].mean(dim=0) for c in clusters])\n",
    "\n",
    "\n",
    "merged_one_hot_recon = torch.stack(\n",
    "    [merged_rows[:, c].mean(dim=1) for c in clusters],\n",
    "    dim=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 1 dimensional tensor of size vocab_size to store the indices of the merged clusters\n",
    "index_map = torch.zeros(vocab_size, device=one_hot_recon.device, dtype=torch.long)\n",
    "for i, cluster in enumerate(clusters):\n",
    "    for index in cluster:\n",
    "        index_map[index] = i     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearProbe(\n",
       "  (fc1): Linear(in_features=4096, out_features=20469, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, hdim=hidden_dim, vocab_size=merged_one_hot_recon.shape[0]):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hdim, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.fc1(X)\n",
    "        return x\n",
    "\n",
    "\n",
    "linear_nn = LinearProbe()\n",
    "linear_nn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize reconstructions\n",
    "row_min = torch.min(merged_one_hot_recon, dim=1, keepdim=True)[0]\n",
    "row_max = torch.max(merged_one_hot_recon, dim=1, keepdim=True)[0]\n",
    "range_vals = row_max - row_min\n",
    "# Perform min-max scaling for each row\n",
    "scaled_matrix = (merged_one_hot_recon - row_min) / range_vals\n",
    "# Control sparisty by raising the scaled values to a power\n",
    "exp = 2\n",
    "scaled_matrix = torch.pow(scaled_matrix, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.400e+01, 1.261e+03, 3.301e+03, 3.243e+03, 2.643e+03, 2.845e+03,\n",
       "        2.652e+03, 1.977e+03, 1.155e+03, 6.340e+02, 3.040e+02, 1.430e+02,\n",
       "        8.400e+01, 4.000e+01, 2.300e+01, 1.800e+01, 8.000e+00, 6.000e+00,\n",
       "        3.000e+00, 6.000e+00, 3.000e+00, 2.000e+00, 1.000e+00, 4.000e+00,\n",
       "        0.000e+00, 1.000e+00, 1.000e+00, 5.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([ 808.02075195,  891.58624268,  975.1517334 , 1058.71716309,\n",
       "        1142.28271484, 1225.84814453, 1309.41357422, 1392.97900391,\n",
       "        1476.54455566, 1560.11010742, 1643.67553711, 1727.2409668 ,\n",
       "        1810.80639648, 1894.37194824, 1977.93737793, 2061.50292969,\n",
       "        2145.06835938, 2228.63378906, 2312.19921875, 2395.76464844,\n",
       "        2479.33032227, 2562.89575195, 2646.46118164, 2730.02685547,\n",
       "        2813.59228516, 2897.15771484, 2980.72314453, 3064.28857422,\n",
       "        3147.85400391, 3231.41943359, 3314.98510742, 3398.55053711,\n",
       "        3482.1159668 , 3565.68139648, 3649.24682617, 3732.8125    ,\n",
       "        3816.37792969, 3899.94335938, 3983.50878906, 4067.07421875,\n",
       "        4150.63964844, 4234.20507812, 4317.77050781, 4401.3359375 ,\n",
       "        4484.90136719, 4568.46679688, 4652.03271484, 4735.59814453,\n",
       "        4819.16357422, 4902.72900391, 4986.29492188, 5069.86035156,\n",
       "        5153.42578125, 5236.99121094, 5320.55664062, 5404.12207031,\n",
       "        5487.6875    , 5571.25292969, 5654.81835938, 5738.38378906,\n",
       "        5821.94921875, 5905.51464844, 5989.08007812, 6072.64550781,\n",
       "        6156.2109375 , 6239.77636719, 6323.34179688, 6406.90722656,\n",
       "        6490.47265625, 6574.03808594, 6657.60449219, 6741.16992188,\n",
       "        6824.73535156, 6908.30078125, 6991.86621094, 7075.43164062,\n",
       "        7158.99707031, 7242.5625    , 7326.12792969, 7409.69335938,\n",
       "        7493.25878906, 7576.82421875, 7660.38964844, 7743.95507812,\n",
       "        7827.52050781, 7911.0859375 , 7994.65136719, 8078.21679688,\n",
       "        8161.78222656, 8245.34765625, 8328.91308594, 8412.47949219,\n",
       "        8496.04492188, 8579.61035156, 8663.17578125, 8746.74121094,\n",
       "        8830.30664062, 8913.87207031, 8997.4375    , 9081.00292969,\n",
       "        9164.56835938]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Measure sparisty of each row in reconstructions with sum\n",
    "sparsity = torch.sum(scaled_matrix, dim=1)\n",
    "# plot histogram of sparsity\n",
    "plt.hist(sparsity.cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, label_weight, penalty_weight):\n",
    "        super(WeightedMSELoss, self).__init__()\n",
    "        self.label_weight = label_weight\n",
    "        self.penalty_weight = penalty_weight\n",
    "\n",
    "    def forward(self, predictions, soft_labels, label_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions (torch.Tensor): Model predictions of shape (batch_size, num_classes).\n",
    "            soft_labels (torch.Tensor): Ground truth soft labels of shape (batch_size, num_classes).\n",
    "            label_indices (torch.Tensor): Indices of the target label for each batch item. Shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The weighted MSE loss.\n",
    "        \"\"\"\n",
    "        batch_size, _ = predictions.size()\n",
    "        weights = torch.ones_like(predictions)\n",
    "        weights[torch.arange(batch_size), label_indices] = self.label_weight\n",
    "        squared_diff = (predictions - soft_labels) ** 2\n",
    "        weighted_squared_diff = squared_diff * weights\n",
    "        mess_loss = weighted_squared_diff.mean()\n",
    "\n",
    "        penalty = torch.clamp(-predictions, min=0)  # Penalize only values <= 0\n",
    "        penalty_loss = self.penalty_weight * penalty.sum() / predictions.numel()\n",
    "\n",
    "        return mess_loss + penalty_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 11\n",
    "learning_rate = 5e-5\n",
    "\n",
    "mse_criterion = WeightedMSELoss(label_weight=20, penalty_weight=0)\n",
    "optimizer = torch.optim.AdamW(linear_nn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 41.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 with Train Loss:  0.010029754601418972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5009it [01:06, 73.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000 with Train Loss:  0.01216174941509962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10009it [02:13, 73.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000 with Train Loss:  0.4112742841243744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15013it [03:21, 73.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000 with Train Loss:  0.00938702467828989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20013it [04:28, 76.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000 with Train Loss:  0.009219292551279068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20480it [04:34, 74.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Val Acc:  tensor(0.2853, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 with Train Loss:  0.007569699082523584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [01:05, 76.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000 with Train Loss:  0.008725094608962536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10012it [02:09, 76.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000 with Train Loss:  0.0081334775313735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15012it [03:15, 76.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000 with Train Loss:  0.01085115596652031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20012it [04:20, 76.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000 with Train Loss:  0.008357030339539051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20480it [04:26, 76.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Val Acc:  tensor(0.3396, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 with Train Loss:  0.006608347874134779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [01:05, 76.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000 with Train Loss:  0.010813554748892784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10012it [02:11, 76.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000 with Train Loss:  0.009229595772922039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15012it [03:16, 76.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000 with Train Loss:  0.11964031308889389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20012it [04:21, 76.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000 with Train Loss:  0.07680076360702515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20480it [04:28, 76.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Val Acc:  tensor(0.3659, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 with Train Loss:  0.008155073039233685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [01:05, 76.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000 with Train Loss:  0.008667193353176117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10012it [02:10, 76.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000 with Train Loss:  0.00918000377714634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15011it [03:16, 76.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000 with Train Loss:  0.008022366091609001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20009it [04:21, 76.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000 with Train Loss:  0.009851804934442043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20480it [04:28, 76.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Val Acc:  tensor(0.3885, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 39.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 with Train Loss:  0.009374614804983139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5012it [01:05, 70.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5000 with Train Loss:  0.09449932724237442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10012it [02:11, 76.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10000 with Train Loss:  0.009687623009085655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15012it [03:16, 76.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15000 with Train Loss:  0.20051933825016022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20012it [04:21, 76.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20000 with Train Loss:  0.010287520475685596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20480it [04:27, 76.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Val Acc:  tensor(0.3928, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_accs = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Training epoch\n",
    "    linear_nn.train()\n",
    "    epoch_train_loss = 0.0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        X = batch[0].to(device)\n",
    "        y = index_map[batch[1].to(device)]\n",
    "        outputs = linear_nn(X)\n",
    "        soft_labels = scaled_matrix[y]\n",
    "        loss = mse_criterion(outputs, soft_labels, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(f'Step: {i} with Train Loss: ', loss.item())\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # validation epoch\n",
    "    linear_nn.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_dataloader):\n",
    "            X = batch[0].to(device)\n",
    "            y = index_map[batch[1].to(device)]\n",
    "            outputs = linear_nn(X)\n",
    "            labels = outputs.argmax(dim=1)\n",
    "            correct += (labels == y).sum()\n",
    "\n",
    "    val_accuracy = correct / X_val.shape[0]\n",
    "    val_accs.append(val_accuracy.item())\n",
    "\n",
    "    print(\"Epoch: {} | Val Acc: \".format(epoch+1), correct/X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy:  0.3927764892578125\n",
      "Top-3 Accuracy:  0.5523406982421875\n"
     ]
    }
   ],
   "source": [
    "linear_nn.eval()\n",
    "\n",
    "correct_top1 = 0\n",
    "correct_top3 = 0\n",
    "# Let's calculate the accuracy on the validation set\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        y = index_map[batch[1].to(device)]\n",
    "\n",
    "        outputs = linear_nn(X)\n",
    "\n",
    "        # Top-1 accuracy\n",
    "        labels_top1 = outputs.argmax(dim=1)\n",
    "        correct_top1 += (labels_top1 == y).sum()\n",
    "\n",
    "        # Top-3 accuracy\n",
    "        top3_preds = torch.topk(outputs, k=3, dim=1).indices\n",
    "        correct_top3 += sum([y[j] in top3_preds[j] for j in range(len(y))])\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy_top1 = correct_top1.item() / len(X_val)\n",
    "accuracy_top3 = correct_top3 / len(X_val)\n",
    "\n",
    "print(\"Top-1 Accuracy: \", accuracy_top1)\n",
    "print(\"Top-3 Accuracy: \", accuracy_top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_nn.state_dict(), 'saved_models/linear_probe_reduced.pth')\n",
    "raise\n",
    "# linear_nn.load_state_dict(torch.load(\"saved_models/linear_probe_sigmoid-bce_lr1e-3_epoch3_seed42.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "\n",
    "##### Some qualitative checks on the linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, hdim=hidden_dim, vocab_size=len(tokenizer)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hdim, vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        x = self.fc1(X)\n",
    "        return x\n",
    "\n",
    "linear_nn = LinearProbe()\n",
    "linear_nn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = 'saved_models/linear_probe_pinv-mse_lr1e-4_epoch4_exp7_lw60_pw0.5_seed42.pth'\n",
    "linear_nn.load_state_dict(torch.load(model_path))\n",
    "#linear_nn.load_state_dict(torch.load('saved_models/linear_probe_f2-f3_lr1e-3_epoch3_seed42_temp3.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the accuracy on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_nn.eval()\n",
    "\n",
    "correct = 0\n",
    "# Let's calculate the accuracy on the validation set\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        outputs = linear_nn(X)\n",
    "        labels = outputs.argmax(dim=1)\n",
    "\n",
    "        correct += (labels == y).sum()\n",
    "\n",
    "print(\"Accuracy: \", correct.item()/X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some manual qualititive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check max and min values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every X in val_dataloader, get the output from linear_nn and find the top prediction value and plot it\n",
    "top_values = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        outputs = linear_nn(X)\n",
    "        top_values.extend(outputs.max(dim=1).values.cpu().numpy())\n",
    "        \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(top_values, bins=100)\n",
    "plt.xlabel('Top Prediction Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top Prediction Value Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every X in val_dataloader, get the output from linear_nn and find the top prediction value and plot it\n",
    "top_values = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        outputs = linear_nn(X)\n",
    "        top_values.extend(outputs.min(dim=1).values.cpu().numpy())\n",
    "        \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(top_values, bins=100)\n",
    "plt.xlabel('Min Prediction Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top Prediction Value Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores_batch(outputs, indices, epsilon=1e-8, alpha=3):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        outputs (torch.Tensor): A 2D tensor of shape (batch_size, num_classes), containing the model's outputs.\n",
    "        indices (torch.Tensor): A 1D tensor of shape (batch_size,), containing the target indices.\n",
    "        epsilon (float): A small constant to avoid division by zero.\n",
    "        alpha (float): A scaling factor to penalize smaller differences.\n",
    "    Returns:\n",
    "        torch.Tensor: A 1D tensor of scores for all samples in the batch.\n",
    "    \"\"\"\n",
    "    # Gather the target values using indices\n",
    "    batch_size = outputs.size(0)\n",
    "    num_classes = outputs.size(1)\n",
    "\n",
    "    # Select the target values for each sample\n",
    "    v_target = outputs[torch.arange(batch_size), indices]\n",
    "\n",
    "    # Compute the difference by subtracting outputs from target values\n",
    "    diff = v_target.unsqueeze(1) - outputs\n",
    "\n",
    "    # Exclude the target index by setting its difference to zero\n",
    "    diff[torch.arange(batch_size), indices] = 0.0\n",
    "\n",
    "    # Apply penalization: smaller differences are penalized more\n",
    "    penalized_diff = diff ** alpha\n",
    "\n",
    "    # Compute the average penalized difference for each sample\n",
    "    scores = penalized_diff.sum(dim=1) / (num_classes - 1)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Process the entire validation set\n",
    "all_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        X = batch[0].to(device)  # Inputs\n",
    "        y = batch[1].to(device)  # Target indices\n",
    "        outputs = linear_nn(X)  # Model outputs (logits or predictions)\n",
    "\n",
    "        # Compute batch scores without a loop\n",
    "        batch_scores = compute_scores_batch(outputs, y)\n",
    "        all_scores.append(batch_scores)\n",
    "\n",
    "all_scores = torch.cat(all_scores, dim=0)\n",
    "\n",
    "# Concatenate scores and compute the average score\n",
    "average_score = torch.mean(all_scores)\n",
    "\n",
    "print(f\"Average Sparsity Score: {average_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every X in val_dataloader, get the output from linear_nn and find the top prediction value and plot it\n",
    "top_values = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        outputs = linear_nn(X)\n",
    "        # find difference between top 2 values\n",
    "        top2 = outputs.topk(10, dim=1).values.cpu().numpy()\n",
    "        top_values.extend(top2[:,0] - top2[:, 1])\n",
    "        \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(top_values, bins=100)\n",
    "plt.xlabel('Top 2 Diff')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Top 2 Diff Value Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values like between -0.1 and 1\n",
    "min = -0.31\n",
    "max = 1.3\n",
    "linear_nn.eval()\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X = batch[0].to(device)\n",
    "        outputs = linear_nn(X)\n",
    "        mask = (outputs <= min) | (outputs >= max)\n",
    "        filtered_tensor = outputs[mask]\n",
    "        assert filtered_tensor.shape[0] == 0, f\"Invalid values found: {filtered_tensor}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_nn.eval()\n",
    "# sample data from val_dataloader\n",
    "X, y = next(iter(val_dataloader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "outputs = linear_nn(X)\n",
    "# plot ouputs\n",
    "plt.figure(figsize=(10, 6))\n",
    "idx = 25\n",
    "\n",
    "plt.plot(outputs[idx].detach().cpu().numpy())\n",
    "top2 = outputs[idx].topk(2, dim=0).indices\n",
    "print(top2)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(top2))\n",
    "print(y[idx])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_entropy(logits):\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    log_probabilities = F.log_softmax(logits, dim=-1)\n",
    "    entropy = -torch.sum(probabilities * log_probabilities, dim=-1)\n",
    "    return entropy\n",
    "\n",
    "linear_nn.eval()\n",
    "entropies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        X = batch[0].to(device)\n",
    "        outputs = linear_nn(X)\n",
    "        entropy = calculate_entropy(outputs)\n",
    "        entropies.append(entropy.cpu())\n",
    "\n",
    "entropies = torch.cat(entropies).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(entropies, bins=100, kde=True)\n",
    "plt.xlabel('Entropy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Entropy Distribution of Validation Outputs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 40\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.histplot(outputs[idx].cpu(), bins=20, kde=True)\n",
    "plt.show()\n",
    "\n",
    "outputs[idx].topk(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: \", outputs[idx].mean().item())\n",
    "print(\"Std Deviation: \", outputs[idx].std().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build watermark matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembedding = model.lm_head.weight.data\n",
    "\n",
    "\n",
    "rng = torch.Generator(device=unembedding.device)\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "gamma = 0.50\n",
    "hash_key = 15485863\n",
    "\n",
    "\n",
    "def prf_lookup(input_ids):\n",
    "    return hash_key * input_ids[-1:].sum().item()\n",
    "\n",
    "\n",
    "def get_partition(input_ids):\n",
    "    prf_key = prf_lookup(input_ids)\n",
    "    rng.manual_seed(prf_key % (2**64 - 1))\n",
    "\n",
    "    greenlist_size = int(vocab_size * gamma)\n",
    "    vocab_permutation = torch.randperm(\n",
    "        vocab_size, device=unembedding.device, generator=rng)\n",
    "    greenlist_ids = vocab_permutation[:greenlist_size].to(\"cpu\")\n",
    "    redlist_ids = vocab_permutation[greenlist_size:].to(\"cpu\")\n",
    "    return greenlist_ids, redlist_ids\n",
    "\n",
    "# values x keys\n",
    "watermark_matrix = torch.zeros(len(tokenizer), len(tokenizer))\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(tokenizer))):\n",
    "    greenlist_ids, redlist_ids = get_partition(torch.tensor([i]))\n",
    "    watermark_matrix[greenlist_ids, i] = 2.0\n",
    "    watermark_matrix[redlist_ids, i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_matrix = watermark_matrix.to(unembedding.device)\n",
    "l = linear_nn.fc1.weight.data.to(unembedding.device)\n",
    "deltas = torch.matmul(watermark_matrix, l)\n",
    "assert unembedding.shape == deltas.shape\n",
    "augmented_unembedding = unembedding + deltas\n",
    "\n",
    "model.lm_head.weight.data = augmented_unembedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "test_text = \"The cat sat on the \"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs, return_dict_in_generate=True,  max_length=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = output.sequences[0]\n",
    "tokenizer.decode(seq, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also do the analysis using the watermark matrix (what i mean when i say i want the logits to be close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_matrix = torch.load(\"data/watermark_matrix_gamma0.50_simple1_key15485863.pt\")\n",
    "\n",
    "# dummy logits where everything is a small positive value\n",
    "# probe_outputs = torch.ones((10, 50277), dtype=torch.float32)/10\n",
    "probe_outputs = outputs\n",
    "wm_predicted = einops.einsum(probe_outputs.cpu(), watermark_matrix.T, \"b i, i j -> b j\")\n",
    "\n",
    "print(\"Watermark Delta Prediction: \", wm_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenlist_ids, redlist_ids = get_partition(torch.tensor([187]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Green List: \", wm_predicted[0, greenlist_ids].mean().item())\n",
    "print(\"Mean Red List: \", wm_predicted[0, redlist_ids].mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.histplot(wm_predicted[0, greenlist_ids].cpu(), bins=30, kde=True, color=\"green\")\n",
    "# sns.histplot(wm_predicted[0, redlist_ids].cpu(), bins=30, kde=True, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Magnitude of the Logits :- Clean Analysis of the Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check how biased these logits are using this loss: f2 + f3 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.histplot(wm_predicted[7].cpu(), bins=30, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenlist_ids, redlist_ids = get_partition(torch.tensor([y[6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "sns.histplot(wm_predicted[6, greenlist_ids].cpu(), bins=30, kde=True, color=\"green\")\n",
    "sns.histplot(wm_predicted[6, redlist_ids].cpu(), bins=30, kde=True, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the MSE loss on the watermark logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_matrix = torch.load(\"data/watermark_matrix_gamma0.50_simple1_key15485863.pt\")\n",
    "# watermark_matrix = watermark_matrix.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "linear_nn.eval()\n",
    "\n",
    "total_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(val_dataloader)):\n",
    "        X = batch[0]\n",
    "        y = batch[1]\n",
    "\n",
    "        y_onehot = F.one_hot(y, num_classes=len(tokenizer)).to(torch.float32)\n",
    "        y_onehot = y_onehot\n",
    "\n",
    "        outputs = linear_nn(X.to(device))\n",
    "        outputs = torch.sigmoid(outputs).to(\"cpu\")\n",
    "\n",
    "        wm_predicted = einops.einsum(outputs, watermark_matrix.T, \"b i, i j -> b j\")\n",
    "        wm_gt = watermark_matrix[:, y].T\n",
    "\n",
    "        loss = mse_loss(wm_predicted, wm_gt)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i >= 100:\n",
    "            break\n",
    "\n",
    "        #? to check if matrix mult is okay\n",
    "        # wm_generated = einops.einsum(y_onehot, watermark_matrix.T, \"b i, i j -> b j\")\n",
    "        # wm_gt = watermark_matrix[:, y].T\n",
    "        # diff = wm_generated - wm_gt\n",
    "        # print(diff.sum())\n",
    "\n",
    "# len(val_dataloader) * val_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_val_loss = total_loss/100\n",
    "print(avg_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the watermark matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the watermark matrix and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column i of this matrix should be the green-red split for the column i.\n",
    "rng = torch.Generator(device=device)\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "gamma = 0.50\n",
    "hash_key = 15485863\n",
    "\n",
    "def prf_lookup(input_ids):\n",
    "    return hash_key * input_ids[-1:].sum().item()\n",
    "\n",
    "def get_partition(input_ids):\n",
    "    prf_key = prf_lookup(input_ids)\n",
    "    rng.manual_seed(prf_key % (2**64 - 1))\n",
    "\n",
    "    greenlist_size = int(vocab_size * gamma)\n",
    "    vocab_permutation = torch.randperm(vocab_size, device=device, generator=rng)\n",
    "    greenlist_ids = vocab_permutation[:greenlist_size].to(\"cpu\")\n",
    "    redlist_ids = vocab_permutation[greenlist_size:].to(\"cpu\")\n",
    "    return greenlist_ids, redlist_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_matrix = torch.zeros(len(tokenizer), len(tokenizer))\n",
    "\n",
    "for i in tqdm(range(len(tokenizer))):\n",
    "    greenlist_ids, redlist_ids = get_partition(torch.tensor([i]))\n",
    "    watermark_matrix[greenlist_ids, i] = 1.0\n",
    "    watermark_matrix[redlist_ids, i] = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(watermark_matrix, \"data/watermark_matrix_gamma0.50_simple1_key15485863.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the watermark matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_matrix = torch.load(\"data/watermark_matrix_gamma0.50_simple1_key15485863.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hidden Layer NN with second matrix frozen as the watermark matrix\n",
    "\n",
    "Things tried\n",
    "\n",
    "- Regression loss between the multi-hot encoded vectors and logits (does not work well).\n",
    "- Formulate the problem as multi-label classification problem. `saved as config 2`\n",
    "- Loss as the cosine similarity between the outputs of the model and watermark logits (make it +1 and -1).\n",
    "\n",
    "TODO:\n",
    "\n",
    "- [] Capped ReLU.\n",
    "- [] Sparsity in the intermediate representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatermarkNetwork(nn.Module):\n",
    "    def __init__(self, hdim=2048, vocab_size=len(tokenizer), watermark_matrix=None):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hdim, vocab_size)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(vocab_size, vocab_size)\n",
    "\n",
    "        # set the watermark matrix as the second layer\n",
    "        self.fc2.weight = nn.Parameter(watermark_matrix, requires_grad=False)\n",
    "        self.fc2.bias = nn.Parameter(torch.zeros(vocab_size), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmNet = WatermarkNetwork(watermark_matrix=watermark_matrix)\n",
    "wmNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will try training the neural network with a regression loss on the watermark outputs\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# freeze the second layer\n",
    "wmNet.fc2.weight.requires_grad = False\n",
    "wmNet.fc2.bias.requires_grad = False\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(wmNet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in wmNet.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in wmNet.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch  in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        output = wmNet(X)\n",
    "        targets = watermark_matrix[:, y.to(\"cpu\")]\n",
    "        targets = targets.permute(1, 0).to(device)\n",
    "\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Step [{i + 1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(wmNet.state_dict(), 'saved_models/wm_config2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some text and (1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
